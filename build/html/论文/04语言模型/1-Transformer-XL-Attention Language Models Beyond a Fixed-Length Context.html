<!DOCTYPE html>
<html class="no-js" lang="zh-CN">
<head>
    <meta charset="utf-8" />
        <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
        <title>1-Transformer-XL-Attention Language Models Beyond a Fixed-Length Context &mdash; SphinxDiary v1.0 文档</title>
    
    <link rel="stylesheet" type="text/css" href="../../_static/dist/fontawesome.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/dist/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
            <link rel="index" title="索引" href="../../genindex.html" />
            <link rel="search" title="搜索" href="../../search.html" />
            <link rel="top" title="SphinxDiary v1.0 文档" href="#" />
            <link rel="up" title="语言模型" href="../4-index.html" />
            <link rel="prev" title="语言模型" href="../4-index.html" />
    </head>
<body>
    <script type="text/javascript" src="../../_static/dist/blocking.js"></script>
    <header class="container-fluid bg-primary">
        <a class="btn btn-sm btn-light skip-to-content-link" href="#main">Skip to content</a>
        <div class="container-fluid">
            <div class="navbar navbar-expand-lg navbar-dark font-weight-bold">
                    <a href="../../index.html"
                        title="Wagtail"
                        class="logo navbar-brand"
                    >
                        <img src="../../_static/img/wagtail-logo-new.svg" width="45" height="59" alt="Wagtail"
                            class="logo-img"
                        />
                        Sphinx Wagtail Theme
                    </a>
                
                
                <button class="navbar-toggler btn btn-primary d-lg-none" type="button" data-toggle="collapse" data-target="#collapseSidebar" aria-expanded="false" aria-controls="collapseExample">
                    <span class="navbar-toggler-icon"></span>
                    <span class="sr-only">menu</span>
                </button>
            </div>
        </div>
    </header>
    <div class="container-fluid">
        <div class="row">
            <aside class="col-12 col-lg-3 sidebar-container">
                <div id="collapseSidebar" class="collapse sticky-top d-lg-block pt-5 pr-lg-4">
<div id="searchbox" class="searchbox mb-6 px-1" role="search">
    <form id="search-form" action="../../search.html" autocomplete="off" method="get" role="search">
        <div class="input-group">
            <div class="input-group-prepend">
                <div class="input-group-text border-right-0 bg-white py-3 pl-3 pr-2"><span class="fas fa-search"></span></div>
            </div>
            <input class="form-control py-3 pr-3 pl-1 h-100 border-left-0" type="search" name="q" placeholder="Search documentation" aria-label="Search documentation" id="searchinput" />
        </div>
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
    </form>
</div><div class="site-toc">
    <nav class="toc mt-3" aria-label="Main menu">
        <p class="caption" role="heading"><span class="caption-text">笔记:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/1-index.html">Docker</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/01Docker/01Docker%E6%96%B0%E5%BB%BA%E7%94%A8%E6%88%B7.html">Docker新建用户</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/01Docker/02Docker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C.html">Docker基本操作</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/01Docker/03Docker%E5%AE%B9%E5%99%A8%E5%A4%87%E4%BB%BD%E4%B8%8E%E8%BF%81%E7%A7%BB.html">Docker容器备份与迁移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/2-index.html">Kubernetes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/02Triton_with_kubernetes/01%E5%9C%A8Ubuntu18.04%E4%B8%8A%E6%90%AD%E5%BB%BAkubernetes.html">kubernetes安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/02Triton_with_kubernetes/02%E4%BD%BF%E7%94%A8MIG%E5%92%8CKubernetes%E5%A4%A7%E8%A7%84%E6%A8%A1%E9%83%A8%E7%BD%B2NVIDIA%20Triton.html">Kubernetes部署NVIDIA Triton</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/02Triton_with_kubernetes/03%E4%BD%BF%E7%94%A8Kubernetes%E5%88%9B%E5%BB%BA%E9%9B%86%E7%BE%A4.html">Kubernetes创建集群</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/02Triton_with_kubernetes/04Triton%20Metrics.html">Triton Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/02Triton_with_kubernetes/05Grafana.html">Grafana</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/3-index.html">Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/03Triton/01Triton_Inference_Server%E5%85%A5%E9%97%A8.html">Triton Inference Server入门</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/03Triton/02Triton%E5%85%A5%E9%97%A8%E7%BA%A7%E6%95%99%E7%A8%8B.html">Triton入门级教程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/03Triton/03Triton_Backend%E8%AF%A6%E8%A7%A3.html">Triton_Backend详解</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/4-index.html">Pytorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/04Pytorch/01%E6%95%B0%E6%8D%AE%E9%9B%86.html">数据集</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/5-index.html">语音识别环境部署教程</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/05%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/01jetpack5.0.2%E5%AE%89%E8%A3%85.html">Jetpack 5.0.2安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/05%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/02%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE.html">深度学习环境配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/05%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/03%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2.html">语音识别模型部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/05%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/04%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86.html">客户端模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/05%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/05%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95.html">性能测试</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/6-index.html">小工具</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/01Git.html">Git</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/2-index.html">Sphinx</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/02Sphinx/01GitHub%20%2B%20Spinx%20%2B%20Read%20the%20docs%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%EF%BC%88%E4%B8%80%EF%BC%89.html">GitHub + Spinx + Read the docs实战入门指南（一）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/02Sphinx/02GitHub%20%2B%20Spinx%20%2B%20Read%20the%20docs%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%EF%BC%88%E4%BA%8C%EF%BC%89.html">GitHub + Spinx + Read the docs实战入门指南（二）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/02Sphinx/03Markdown.html">Markdown</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/02Sphinx/04MyST-Parser.html">MyST-Parser</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/03Fastertransformer.html">Fastertransformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/04FileBrowser.html">FileBrowser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/05NFS%E9%85%8D%E7%BD%AE.html">NFS配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/06%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7.html">服务器文件管理工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/06%E5%B0%8F%E5%B7%A5%E5%85%B7/07StableDiffusion.html">Stable Diffusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/7-index.html">NNI</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/07NNI/01-NNI%E7%A4%BA%E4%BE%8B.html">NNI 示例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/07NNI/02-NNI%E9%83%A8%E7%BD%B2.html">NNI 部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/07NNI/03-NNI%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2.html">NNI神经架构搜索</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/8-index.html">Android</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/08Android/01Android%20APK.html">Android APK</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/9-index.html">Android Studio</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/09Android%20Studio/01Android%E4%BD%BF%E7%94%A8.html">1.导入.aar文件</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/09Android%20Studio/01Android%E4%BD%BF%E7%94%A8.html#app-build-gradle-dependencies">2.在app/build.gradle dependencies中加入：</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/09Android%20Studio/01Android%E4%BD%BF%E7%94%A8.html#id1">3.重新编译工程</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/10-index.html">人脸识别</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/10%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/01%E6%91%84%E5%83%8F%E5%A4%B4%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB.html">1.选择人脸检测模型SCRFD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/10%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/01%E6%91%84%E5%83%8F%E5%A4%B4%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB.html#arcface">2.选择人脸识别模型ArcFace</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../%E7%AC%94%E8%AE%B0/10%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/01%E6%91%84%E5%83%8F%E5%A4%B4%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB.html#usb">3.通过USB口连接摄像头模块</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">论文:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../1-index.html">Fine tuning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../01Fine_tuning/01Prompt%20Tuning.html">Prompt Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01Fine_tuning/02Prompt%20Tuning%20v2.html">Prompt Tuning V2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01Fine_tuning/03Lora.html">LoRA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01Fine_tuning/04ChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E9%AA%8C.html">ChatGLM微调实验</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../2-index.html">语音识别</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/1-index.html">语音识别综述</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/01%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0/1-Recent%20Advance%20in%20End-to-End%20Automatic%20Speech%20Recognition.html">1-Recent Advance in End-to-End Automatic Speech Recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/01%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0/2-A%20Comparative%20Study%20On%20Transformer%20VS%20RNN%20In%20Speech%20Applications.html">2-A Comparative Study On Transformer VS RNN In Speech Applications</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/2-index.html">Wenet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/02Wenet/1-WeNet%20Production%20Oriented%20Streaming%20and%20Non-Streaming%20End-to-End%20Speech%20Recognition%20Toolkit.html">1-WeNet Production Oriented Streaming and Non-Streaming End-to-End Speech Recognition Toolkit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/02Wenet/2-WeNet2.0%20More%20Productive%20End-to-End%20Speech%20Recognition%20Toolkit.html">2-Wenet2.0 More Productive End-to-End Speech Recognition Toolkit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/02Wenet/3-WeNet-LM%E6%A8%A1%E5%9E%8B.html">3-WeNet-LM模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/02Wenet/4-WeNet%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84.html">4-Wenet模型结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/02Wenet/5-WeNet%E5%AE%9E%E9%AA%8C%E5%B0%8F%E7%BB%93.html">5-WeNet实验小结</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/02Wenet/6-WeNet%E9%83%A8%E7%BD%B2.html">6-WeNet部署</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/3-index.html">模型微调</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/03%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/1-FINE-TUNING%20OF%20PRE-TRAINED%20END-TO-END%20SPEECH%20RECOGNITION%20WITH%20GENERATIVE%20ADVERSARIAL%20NETWORKS.html">1-Fine-Tuning Of Pre-trained end-to-end Speech Recognition With Generative Adversarial Networks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/4-index.html">编码器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/04%E7%BC%96%E7%A0%81%E5%99%A8/1-Conformer-Convolution-augmented%20Transformer%20for%20Speech%20Recognition.html">1-Conformer-Convolution-augmented Transformer for Speech Recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/04%E7%BC%96%E7%A0%81%E5%99%A8/2-Paraformer-Fast%20and%20Accurate%20Parallel%20Transformer%20for%20Non-autoregressive.html">2-Paraformer-Fast and Accurate Parallel Transformer for Non-autoregressive</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/04%E7%BC%96%E7%A0%81%E5%99%A8/3-LFEformer-Local_Feature_Enhancement_Using_Sliding_Window_With_Deformability_for_Automatic_Speech_Recognition.html">3-LFEformer-Local Feature Enhancement Using Sliding Window With Deformability for Automatic Speech Recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/04%E7%BC%96%E7%A0%81%E5%99%A8/4-Squeezeformer-An%20Efficient%20Transformer%20for%20Automatic%20Speech%20Recognition.html">4-Squeezeformer-An Efficient Transformer for Automatic Speech Recognition</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../3-index.html">联邦学习</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../03%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/1-index.html">联邦学习项目</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../03%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/01%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/1-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE.html">联邦学习开源项目</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../4-index.html">语言模型</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">1-Transformer-XL-Attention Language Models Beyond a Fixed-Length Context</a></li>
</ul>
</li>
</ul>

    </nav>
    <template data-toggle-item-template>
        <button class="btn btn-sm btn-link toctree-expand" type="button">
            <span class="sr-only">Toggle menu contents</span>
        </button>
    </template>
</div>
                    <div class="d-lg-none border-bottom">
                        
                    </div>
                </div>
            </aside>
            <div class="col-12 col-lg-9 pt-5">
                <header class="row align-items-baseline">
                    <div class="col">
                        <nav aria-label="breadcrumb">
    <ol class="breadcrumb m-0 p-0 bg-transparent">
        <li class="breadcrumb-item"><a href="../../index.html">Docs</a></li>
            <li class="breadcrumb-item"><a href="../4-index.html">语言模型</a></li>
        <li class="breadcrumb-item active" aria-current="page">1-Transformer-XL-Attention Language Models Beyond a Fixed-Length Context</li>
    </ol>
</nav>
                    </div>
                    <div class="col-sm-12 col-lg-auto mt-3 mt-lg-3">
                        <noscript>
                            <p>JavaScript is required to toggle light/dark mode..</p>
                        </noscript>
                        <button id="wagtail-theme" class="btn btn-sm btn-light text-decoration-none" type="button">
                            <span class="dark-only"><i class="fas fa-sun"></i> Light mode</span>
                            <span class="light-only"><i class="fas fa-moon"></i> Dark mode</span>
                        </button>
    <a class="btn btn-sm btn-light text-decoration-none" href="https://github.com/wagtail/sphinx_wagtail_theme/blob/main/docs/论文/04语言模型/1-Transformer-XL-Attention Language Models Beyond a Fixed-Length Context.md" rel="nofollow">
        <span class="btn-icon"><span class="fab fa-github"></span></span>
        <span class="btn-text">Edit on GitHub</span>
    </a>
    <a class="btn btn-sm btn-light text-decoration-none" href="../../_sources/论文/04语言模型/1-Transformer-XL-Attention Language Models Beyond a Fixed-Length Context.md.txt" rel="nofollow">
        <span class="btn-icon"><span class="fas fa-code"></span></span>
        <span class="btn-text">View source</span>
    </a>
                        
                    </div>
                </header>
                <div class="row" >
                    <div class="col-12">
                        <hr class="w-100 my-4">
                    </div>
                </div>
                <div class="row">
                    <div class="col-12 col-lg-9 order-last order-lg-first rst-content">
                        <main role="main" id="main">
    <section class="tex2jax_ignore mathjax_ignore" id="transformer-xl-attention-language-models-beyond-a-fixed-length-context">
<h1>1-Transformer-XL-Attention Language Models Beyond a Fixed-Length Context<a class="headerlink" href="#transformer-xl-attention-language-models-beyond-a-fixed-length-context" title="此标题的永久链接">¶</a></h1>
<p>论文链接：<a class="reference external" href="https://arxiv.org/abs/1901.02860">https://arxiv.org/abs/1901.02860</a></p>
<p>开源代码：<a class="reference external" href="https://github.com/kimiyoung/transformer-xl">https://github.com/kimiyoung/transformer-xl</a></p>
<p>本文提出了一个新的神经架构 Transformer XL，在不破坏时间连续性下实现超过固定长度学习依赖性，由分段递归机制和新颖的位置编码组成，解决了上下文碎片化问题，在短序列和长序列都能获得更好的性能</p>
<section id="id1">
<h2>一、引言<a class="headerlink" href="#id1" title="此标题的永久链接">¶</a></h2>
<p>语言模型需要对长期依赖性进行建模。</p>
<p>AI-Rfou 等人设计了一组辅助损失来训练用于字符级语言建模的深度 Transformer 网络，但训练是在几百个字符固定长度片段上进行的，模型无法捕获超出预定义上下文长度的任何长期依赖关系，且模型不考虑句子的语义边界，缺乏预测前几个符号所必要的上下文信息，出现上下文碎片化问题。</p>
<p>本文提出的  Transformer-XL 架构可以解决固定长度上下文限制，在深度自注意力网络中引入了递归的概念。我们不再从头开始计算每个片段的隐藏状态，而是复用之前片段所获得的隐藏状态，以在段与段之间建立循环连接。信息可以通过循环连接传播，因此可以建立非常长期的依赖关系。本文引入了相对位置编码，以便在不造成时间混乱的情况下实现状态复用。</p>
<p>本文的主要技术贡献包括在纯自注意力模型中引入递归的概念，并推导出一套新的位置编码方案。</p>
</section>
<section id="id2">
<h2>二、相关工作<a class="headerlink" href="#id2" title="此标题的永久链接">¶</a></h2>
<p>语言模型领域取得重大进展，包括设计新的架构更好地编码上下文，改进正则和优化算法，加速 Softmax 计算，丰富输出分布族。</p>
<p>在通用序列模型中，如何捕获长期依赖性是一个长期存在的问题，很多工作是在 LSTM 框架基础上缓解消除梯度问题，本文的工作基于 Transformer 体系结构，表明语言任务受益于学习长期依赖性的能力。</p>
</section>
<section id="id3">
<h2>三、模型<a class="headerlink" href="#id3" title="此标题的永久链接">¶</a></h2>
<p>本文采用标准方法建模条件概率，具体而言，使用可训练神经网络将上下文 <span class="math notranslate nohighlight">\(\bf x_t\)</span> 编码为固定大小的隐藏状态，将其与词嵌入相乘得到 logits，然后将 logits 输入到 Softmax 函数，在下一个 token 上产生分类概率分布</p>
<section id="vanilla-transformer">
<h3>3.1 Vanilla Transformer 语言模型<a class="headerlink" href="#vanilla-transformer" title="此标题的永久链接">¶</a></h3>
<p>Transformer 应用于语言建模的核心问题是如何训练 Transformer 将任意长的文本有效编码为固定的上下文表征。如果给定无限内存和计算，一个简单的解决方案是使用无条件 Transformer 解码器处理整个上下文序列，类似于一个前馈神经网络，然而在有限资源下通常不可行。</p>
<p>一种可行但粗略的方案是将整个语料库分割成较短的片段，只在每个片段中训练模型，忽略之前片段的所有上下文信息，这是 AI Rfou 等人采用的观点，称之为 vanilla 模型，如图  <strong>1 (a)</strong>  所示，在这种模式下，无论前向传输还是后向传输，信息流都不会跨段移动，但使用固定长度的上下文具有限制。首先，最大依赖长度是片段长度的上限；其次，简单将序列分块为固定长度将会导致上下文碎片的问题。</p>
<p>在评估阶段，每一步 Vanilla 模型都会采用与训练长度相同的片段，在最后一个位置进行预测，在下一步该片段向右移动一个位置而后从头处理新的片段，如图 <strong>1(b)</strong> 所示，确保每个预测利用了训练期间的最长可能的上下文，并缓解了训练过程中上下文碎片化的问题，然而这种评估非常浪费，我们将证明我们的架构能显著提高评估速度。</p>
<p><img alt="" src="../../_images/image-20230620112309045.png" /></p>
</section>
<section id="id4">
<h3>3.2 状态复用的分层递归<a class="headerlink" href="#id4" title="此标题的永久链接">¶</a></h3>
<p>为了解决使用固定长度上下文所带来的局限性，本文在 Transformer 架构中引入递归机制。在训练过程中，为前一个片段计算的隐藏特征序列是固定的，被保存起来，以便模型处理下一个片段时作为扩展的内容进行复用，如图 <strong>2(a)</strong> 所示，这种额外输入允许网络利用历史信息，从而实现长期的依赖性建模，并避免上下文碎片化问题。</p>
<p>这种递归机制应用于语料库每两个连续的片段，本质是在隐藏状态下创建片段级的递归，实际上所利用的上下文远超这两个部分，考虑到递归依赖性 <span class="math notranslate nohighlight">\(\bf h_{\tau+1}^n\)</span> 和 <span class="math notranslate nohighlight">\(\bf h_{\tau}^{n-1}\)</span> 之间相差了一层，不同于传统 RNN 中的同层递归，最大可能的依赖长度随着层数和分段的长度线性增长，即 <span class="math notranslate nohighlight">\(O(N \times L)\)</span>，如图 2 中的阴影部分所示。</p>
<p><img alt="" src="../../_images/image-20230620154221270.png" /></p>
<p>除了实现超长上下文及解决碎片化问题外，递归方案的另一个好处是大大加快了评估速度。在评估过程中，可以复用先前片段的表征，而不是像 vanilla 那样从头开始计算，在我们的 enwiki8 实验中，评估速度比 vanilla 模型快了 1800+ 倍。</p>
<p>最后，注意到递归方案不需要仅限于前一个片段，只要在 GPU 内存允许的情况下可以缓存尽可能多的先前片段。我们可以缓存预定义长度为 <span class="math notranslate nohighlight">\(M\)</span> 的跨越多个片段的旧隐藏状态，放到内存中，与记忆增强神经网络相联系。在我们的实验中设置 <span class="math notranslate nohighlight">\(M\)</span> 等于片段长度，该值在评估过程中多次增加。</p>
</section>
<section id="id5">
<h3>3.3 相对位置编码<a class="headerlink" href="#id5" title="此标题的永久链接">¶</a></h3>
<p>为了复用隐藏状态，还有一个关键挑战是如何保持位置信息的一致性。在标准的 Transformer 中，序列顺序信息是由一组位置编码提供，第 <span class="math notranslate nohighlight">\(i\)</span> 行对应于第 <span class="math notranslate nohighlight">\(i\)</span> 个绝对位置，还规定了建模的最大长度。Transformer 的实际输入是将单词嵌入与位置编码元素相加：</p>
<p><img alt="" src="../../_images/image-20230620161908586.png" /></p>
<p>其中 <span class="math notranslate nohighlight">\(\bf E_{s_{\tau}}\)</span> 表示词序列 <span class="math notranslate nohighlight">\(\bf s_{\tau}\)</span> 的嵌入向量，其中 <span class="math notranslate nohighlight">\(\bf E_{s_{\tau}}\)</span> 和 <span class="math notranslate nohighlight">\(\bf E_{s_{\tau+1}}\)</span> 与相同的位置编码相关。因此，模型没有能力区分 <span class="math notranslate nohighlight">\(x_{\tau,j}\)</span> 和 <span class="math notranslate nohighlight">\(x_{\tau+1,j}\)</span> 之间的位置差，会导致性能的损失。</p>
<p>为了避免这种模式，基本思想是只对隐藏状态中的相对位置信息进行编码。原理上，位置编码为模型提供了关于如何收集信息的时间线索，出于同样的目的，可以将相同的信息注入到每一层的注意力得分中，而不是注入到初始嵌入中。以相对的方式定义时间偏置更加直观。例如，将查询向量添加到键向量时，不需要知道每一个键向量的绝对位置来识别片段的时间顺序，相反，只需要知道每个键向量 <span class="math notranslate nohighlight">\(k_{\tau,j}\)</span> 与查询  <span class="math notranslate nohighlight">\(q_{\tau,i}\)</span> 本身的相对距离 <span class="math notranslate nohighlight">\(i-j\)</span> 即可。实际上，可以创建一组相对位置编码 <span class="math notranslate nohighlight">\(\bf R\)</span>，其中第 <span class="math notranslate nohighlight">\(i\)</span> 行表示两个位置之间的相对距离，通过将相对距离动态注入到注意力得分中，查询向量可以很轻松区分 <span class="math notranslate nohighlight">\(x_{\tau,j}\)</span> 和 <span class="math notranslate nohighlight">\(x_{\tau+1,j}\)</span> 来自不同距离的表征，因为绝对位置可以从相对距离中恢复，同时不会丢失任何时间信息。</p>
<p>此前，相对编码的概念已经在机器翻译和音乐生成上进行了探索。这里提供了一个不同的推到，得出一种新的形式的相对位置编码，不仅与绝对位置编码有一对一的映射关系，而且经验上具有更好的泛化能力。首先，在标准 Transformer 中，同一片段内的查询 <span class="math notranslate nohighlight">\(q_i\)</span> 和键向量 <span class="math notranslate nohighlight">\(k_j\)</span> 之间的注意力得分可以分解为：</p>
<p><img alt="" src="../../_images/image-20230621104017705.png" /></p>
<p>将下面四项进行重参数化：</p>
<p><img alt="" src="../../_images/image-20230621104600128.png" /></p>
<ul class="simple">
<li><p>第一个改变是将 (b) 和 (d) 键向量的绝对位置嵌入 <span class="math notranslate nohighlight">\(\bf U_j\)</span> 替换为相对嵌入 <span class="math notranslate nohighlight">\(\bf R_{i-j}\)</span>，注意到，<span class="math notranslate nohighlight">\(\bf R\)</span> 是没有可学习参数的正弦编码矩阵</p></li>
<li><p>第二个改变是引入了可学习参数 <span class="math notranslate nohighlight">\(u\)</span> 取代 © 中的查询项 <span class="math notranslate nohighlight">\(\bf U_i^{T} \bf W_q^{T}\)</span>，这种情况下，所有查询位置的查询向量都是相同的，无论查询位置如何，对不同单词的注意力偏向都应保持不变。类似的，在 (d) 中也添加了同样的替换。</p></li>
<li><p>最后，有意分离两个权重矩阵 <span class="math notranslate nohighlight">\(\bf W_{k,E}\)</span> 和 <span class="math notranslate nohighlight">\(\bf W_{k,R}\)</span>，用于分别产生基于内容的键向量和基于位置的键向量。</p></li>
</ul>
<p>在新的参数化下，每个式子都具有其直观的含义：</p>
<ul class="simple">
<li><p>(a) 表征内容项</p></li>
<li><p>(b) 捕获内容的位置偏差</p></li>
<li><p>© 管理内容的全局偏差</p></li>
<li><p>(d) 编码一个全局位置偏差</p></li>
</ul>
<p>我们的相对位置嵌入 <span class="math notranslate nohighlight">\(\bf R\)</span> 更适用于正弦公式，我们在某个特定长度的记忆单元上训练的模型可以在评估过程中自动推广到多个几倍长的记忆。</p>
<p>将我们提出的递归机制与相对位置嵌入相结合，最终得出了 Transformer-XL 结构。这里总结了具有单注意力头的 N 层 Transformer-XL 的计算过程，对于 <span class="math notranslate nohighlight">\(n=1\)</span>：</p>
<p><img alt="" src="../../_images/image-20230621110358105.png" /></p>
<p>其中 <span class="math notranslate nohighlight">\(\omicron\)</span> 表示两个隐藏向量的级联，其中 <span class="math notranslate nohighlight">\(\bf h_{\tau}^{0}\)</span> 表示词嵌入序列 <span class="math notranslate nohighlight">\(\bf E_{s_{\tau}}\)</span>。</p>
</section>
</section>
<section id="id6">
<h2>四、实验结果<a class="headerlink" href="#id6" title="此标题的永久链接">¶</a></h2>
<p>表 2 我们的模型与最先进结果的比较，12 层 Transformer-XL 获得了新的 SoTA 结果。为了观察是否可以通过增加模型大小来获得更好的性能，我们训练了模型大小 18 和 24 层的 Transformer-XL。训练期间的注意力长度为 784，评估期间的长度为 3800。得益于更好的模型架构，Transformer-XL 不需要任何辅助损失。</p>
<p><img alt="" src="../../_images/image-20230622112829351.png" /></p>
</section>
</section>

</main>
                        <nav aria-label="Page navigation" class="py-4 my-5 clearfix font-weight-bold border-top">
    <a class="float-left" href="../4-index.html" title="Previous">
        <span aria-hidden="true">←&nbsp;</span>语言模型
    </a>
</nav>
                    </div>
                    
                    <nav class="col-12 col-lg-3 pb-4">
                        <div class="sticky-top toc page-toc" aria-labelledby="page-toc-heading">
                            <p class="font-weight-bold" id="page-toc-heading">Page contents</p>
                            <ul>
<li><a class="reference internal" href="#">1-Transformer-XL-Attention Language Models Beyond a Fixed-Length Context</a><ul>
<li><a class="reference internal" href="#id1">一、引言</a></li>
<li><a class="reference internal" href="#id2">二、相关工作</a></li>
<li><a class="reference internal" href="#id3">三、模型</a><ul>
<li><a class="reference internal" href="#vanilla-transformer">3.1 Vanilla Transformer 语言模型</a></li>
<li><a class="reference internal" href="#id4">3.2 状态复用的分层递归</a></li>
<li><a class="reference internal" href="#id5">3.3 相对位置编码</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6">四、实验结果</a></li>
</ul>
</li>
</ul>

                        </div>
                    </nav>
                    
                </div>
            </div>
        </div>
    </div>
    <footer class="container-fluid bg-primary text-light">
        <div class="container">
            <div class="row">
        <div class="col p-4">
            
                <nav aria-label="Footer">
                    <ul class="nav justify-content-center mb-2">
                        
                            
                            
                            <li class="nav-item"><a class="nav-link text-light"  href="https://wagtail.org/features/">Features</a></li>
                        
                            
                            
                            <li class="nav-item"><a class="nav-link text-light"  href="https://wagtail.org/about-wagtail/"> About Wagtail</a></li>
                        
                            
                            
                            <li class="nav-item"><a class="nav-link text-light"  href="https://wagtail.org/services/"> Services</a></li>
                        
                            
                            
                            <li class="nav-item"><a class="nav-link text-light"  href="https://wagtail.org/blog/"> Blog</a></li>
                        
                            
                            
                            <li class="nav-item"><a class="nav-link text-light"  href="https://wagtail.org/packages/"> Packages</a></li>
                        
                            
                            
                            <li class="nav-item"><a class="nav-link text-light"  href="https://wagtail.org/developers/"> Developers</a></li>
                        
                    </ul>
                </nav>
            
            <div class="text-center">
                <p style="display: none">
                    <a class="text-light" href="https://github.com/wagtail/sphinx_wagtail_theme" rel="nofollow" target="_blank">
                        Wagtail Sphinx Theme 6.0.0
                    </a>
                </p>
            </div>
            <div class="text-center">
                    &copy; Copyright 2023, 李仲亮
            </div>
        </div>
    </div>
        </div>
    </footer>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script src="../../_static/translations.js"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script type="text/javascript" src="../../_static/dist/theme.js"></script>
        <script type="text/javascript" src="../../_static/dist/vendor.js"></script>
        <script type="text/javascript" src="../../_static/searchtools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script type="text/javascript">
            document.addEventListener('DOMContentLoaded', function() { Search.loadIndex("../../searchindex.js"); });
        </script>
        <script type="text/javascript" id="searchindexloader"></script>
    </body>
</html>